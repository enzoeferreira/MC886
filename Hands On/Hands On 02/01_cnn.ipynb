{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### **State University of Campinas - UNICAMP** </br>\n",
        "**Course**: MC886A </br>\n",
        "**Professor**: Marcelo da Silva Reis </br>\n",
        "**TA (PED)**: Marcos Vinicius Souza Freire\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "-lGo496ETxPE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Hands-On: Deep Learnng with PyTorch**\n",
        "##### Notebook: 01 CNN\n",
        "---"
      ],
      "metadata": {
        "id": "V84Esge_T1HX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Table of Contents**\n",
        "\n",
        "1. [**Objectives**](#objectives) </br>\n",
        "2. [**Prerequisites**](#prerequisites) </br>\n",
        "3. [**Basic Concept**](#basic-concept) </br>\n",
        "  3.1. [**Deep Neural Network (DNN)**](#1-deep-neural-network-dnn) </br>\n",
        "  3.2. [**Convolutional Neural Network (CNN)**](#2-convolutional-neural-network-cnn) </br>\n",
        "  3.3. [Multi-Layer Perceptron (MLP)](#3-multi--layer-perceptron-mlp) </br>\n",
        "4. [**Implementation of A CNN**](#implementation-of-a-cnn) </br>\n",
        "5. [**Extending CNN with Transfer Learning**](#extending-cnn-with-transfer-learning) </br>\n",
        "6. [**REFERENCES**](#references)\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "-UnOwU0pgXCt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Objectives**\n",
        "- Understand how Convolutional Neural Networks (CNN) are originated and created.\n",
        "- Advance from the single concept of Deep Neural Networks to CNNs.\n",
        "- Understand basic concepts of Transfer Learning and work with Fine-tune.\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "N42neucwaKK1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Prerequisites**\n",
        "- Install PyTorch and some extra packages.\n",
        "- Have Python and a Jupyter Notebook ready (great for interactive demos)."
      ],
      "metadata": {
        "id": "Ti10xotjakOE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Installing Pytorch (for all setups in `00-setup.ipynb` from the hands-on 00):\n",
        "\n",
        "- `pip install torch torchvision`\n",
        "\n",
        "- `pip install nbformat`\n",
        "\n",
        "- `pip install torchmetrics`\n",
        "\n",
        "- To plot pretty graphs, you can use Plotly\n",
        "`pip install plotly`\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "jYsh6pPjamkc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Basic Concept**\n",
        "\n",
        "For this part, let's start with Deep Neural Networks, for a general approach. </br> </br>\n",
        "\n",
        "\n",
        "#### 1. **Deep Neural Network (DNN)**\n",
        "\n",
        "**Definition:**\n",
        "A Deep Neural Network extends the MLP by incorporating multiple hidden layers, enabling the network to learn increasingly complex feature representations at each successive layer. This hierarchical representation learning is what gives deep learning its power to solve complex problems.\n",
        "\n",
        "**Formula:**\n",
        "For a DNN with $L$ hidden layers:\n",
        "\n",
        "First hidden layer ($l=1$): For each neuron $h_j^{(1)}$:\n",
        "$h_j^{(1)} = \\text{activation}^{(1)}(\\sum_{i=0}^{n} w_{ij}^{(1)}x_i)$\n",
        "\n",
        "Hidden layers ($l=2$ to $L$): For each neuron $h_j^{(l)}$:\n",
        "$h_j^{(l)} = \\text{activation}^{(l)}(\\sum_{i=0}^{m_{l-1}} w_{ij}^{(l)}h_i^{(l-1)})$\n",
        "\n",
        "Output layer: For each output neuron $y_j$:\n",
        "$y_j = \\text{activation}^{(L+1)}(\\sum_{i=0}^{m_L} w_{ij}^{(L+1)}h_i^{(L)})$\n",
        "\n",
        "Where:\n",
        "- $h_j^{(l)}$ is the output of the $j$-th neuron in the $l$-th hidden layer\n",
        "- $m_l$ is the number of neurons in the $l$-th layer\n",
        "- $w_{ij}^{(l)}$ is the weight from neuron $i$ in layer $l-1$ to neuron $j$ in layer $l$\n",
        "- $\\text{activation}^{(l)}$ is the activation function for layer $l$ (which may vary by layer)"
      ],
      "metadata": {
        "id": "dZcW0Ywvau2U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import plotly.graph_objects as go\n",
        "\n",
        "# Shared configuration\n",
        "node_size = 40\n",
        "font_size = 12\n",
        "layer_colors = {'input': '#636EFA', 'bias': '#00CC96',\n",
        "               'hidden': '#FFA15A', 'output': '#EF553B',\n",
        "               'activation': '#AB63FA'}\n",
        "\n",
        "def create_network(nodes, edges, title):\n",
        "    fig = go.Figure()\n",
        "    legend_groups = set()\n",
        "\n",
        "    # Create edges with weights\n",
        "    for i, ((src, dest), weight) in enumerate(edges.items()):\n",
        "        x0, y0 = nodes[src]['x'], nodes[src]['y']\n",
        "        x1, y1 = nodes[dest]['x'], nodes[dest]['y']\n",
        "        fig.add_trace(go.Scatter(\n",
        "            x=[x0, x1, None], y=[y0, y1, None],\n",
        "            line=dict(width=1, color='gray'),\n",
        "            mode='lines',\n",
        "            hoverinfo='text',\n",
        "            text=f'Weight: {weight}',\n",
        "            showlegend=i == 0,\n",
        "            legendgroup='weights',\n",
        "            name='Weights'\n",
        "        ))\n",
        "\n",
        "    # Create nodes with legend groups\n",
        "    for node in nodes:\n",
        "        # Determine node type from color\n",
        "        node_type = [k for k, v in layer_colors.items() if v == node['color']][0]\n",
        "\n",
        "        fig.add_trace(go.Scatter(\n",
        "            x=[node['x']], y=[node['y']],\n",
        "            mode='markers+text',\n",
        "            marker=dict(size=node_size, color=node['color']),\n",
        "            text=node.get('label', ''),\n",
        "            textposition=\"top center\",\n",
        "            hoverinfo='text',\n",
        "            hovertext=node.get('formula', ''),\n",
        "            showlegend=node_type not in legend_groups,\n",
        "            legendgroup=node_type,\n",
        "            name=f'{node_type.capitalize()} Node'\n",
        "        ))\n",
        "        if node_type not in legend_groups:\n",
        "            legend_groups.add(node_type)\n",
        "\n",
        "    # Add activation functions as separate traces\n",
        "    activation_added = False\n",
        "    for node in nodes:\n",
        "        if 'activation' in node:\n",
        "            fig.add_trace(go.Scatter(\n",
        "                x=[node['x'] + 0.25],  # Offset from node\n",
        "                y=[node['y'] + 0.1],   # Vertical adjustment\n",
        "                mode='text',\n",
        "                text=node['activation'],\n",
        "                textfont=dict(color=layer_colors['activation'], size=font_size),\n",
        "                showlegend=not activation_added,\n",
        "                legendgroup='activation',\n",
        "                name='Activation Function'\n",
        "            ))\n",
        "            activation_added = True\n",
        "\n",
        "    fig.update_layout(\n",
        "        title=title,\n",
        "        template='plotly_white',\n",
        "        xaxis=dict(showgrid=False, zeroline=False, showticklabels=False),\n",
        "        yaxis=dict(showgrid=False, zeroline=False, showticklabels=False),\n",
        "        margin=dict(l=20, r=150),\n",
        "        legend=dict(\n",
        "            x=1.05,\n",
        "            y=0.5,\n",
        "            xanchor='left',\n",
        "            yanchor='middle',\n",
        "            itemsizing='constant'\n",
        "        )\n",
        "    )\n",
        "    return fig"
      ],
      "metadata": {
        "id": "wnBxeOrabnjv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B97hpNrkTrN2"
      },
      "outputs": [],
      "source": [
        "# --------------------------------------------------------------------------\n",
        "# 1. Deep Neural Network\n",
        "# --------------------------------------------------------------------------\n",
        "dnn_nodes = [\n",
        "    {'x': 0, 'y': 1, 'label': '1', 'color': layer_colors['bias']},\n",
        "    {'x': 0, 'y': 0, 'label': 'x₁', 'color': layer_colors['input']},\n",
        "    {'x': 0, 'y': -1, 'label': 'x₂', 'color': layer_colors['input']},\n",
        "    {'x': 1, 'y': 1.5, 'label': 'h₁₁', 'color': layer_colors['hidden'],\n",
        "     'activation': 'ReLU(Σ)', 'formula': 'h₁₁ = ReLU(Σw¹ᵢxᵢ + b₁)'},\n",
        "    {'x': 1, 'y': 0.5, 'label': 'h₁₂', 'color': layer_colors['hidden'],\n",
        "     'activation': 'ReLU(Σ)', 'formula': 'h₁₂ = ReLU(Σw¹ⱼxⱼ + b₂)'},\n",
        "    {'x': 1, 'y': -0.5, 'label': 'h₁₃', 'color': layer_colors['hidden'],\n",
        "     'activation': 'ReLU(Σ)', 'formula': 'h₁₃ = ReLU(Σw¹ₖxₖ + b₃)'},\n",
        "    {'x': 2, 'y': 1, 'label': 'h₂₁', 'color': layer_colors['hidden'],\n",
        "     'activation': 'tanh(Σ)', 'formula': 'h₂₁ = tanh(Σw²ᵢh₁ᵢ + b₄)'},\n",
        "    {'x': 2, 'y': -1, 'label': 'h₂₂', 'color': layer_colors['hidden'],\n",
        "     'activation': 'tanh(Σ)', 'formula': 'h₂₂ = tanh(Σw²ⱼh₁ⱼ + b₅)'},\n",
        "    {'x': 3, 'y': 0, 'label': 'y', 'color': layer_colors['output'],\n",
        "     'activation': 'σ(Σ)', 'formula': 'y = sigmoid(Σw³ₖh₂ₖ + b₆)'}\n",
        "]\n",
        "\n",
        "dnn_edges = {\n",
        "    (0,3): 'w¹₀₁', (0,4): 'w¹₀₂', (0,5): 'w¹₀₃',\n",
        "    (1,3): 'w¹₁₁', (1,4): 'w¹₁₂', (1,5): 'w¹₁₃',\n",
        "    (2,3): 'w¹₂₁', (2,4): 'w¹₂₂', (2,5): 'w¹₂₃',\n",
        "    (3,6): 'w²₁₁', (3,7): 'w²₁₂',\n",
        "    (4,6): 'w²₂₁', (4,7): 'w²₂₂',\n",
        "    (5,6): 'w²₃₁', (5,7): 'w²₃₂',\n",
        "    (6,8): 'w³₁',\n",
        "    (7,8): 'w³₂'\n",
        "}\n",
        "\n",
        "fig4 = create_network(dnn_nodes, dnn_edges, \"Deep Neural Network (DNN)\")\n",
        "fig4.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. **Convolutional Neural Network (CNN)**\n",
        "\n",
        "**Definition:** A Convolutional Neural Network is a specialized type of neural network designed to process structured grid-like data, such as images or time-series data. CNNs are particularly effective for tasks like image classification, object detection, and facial recognition due to their ability to learn spatial hierarchies of features.\n",
        "\n",
        "**Formula** (simplified for a single convolutional layer):\n",
        "For a feature map $ z $ at position $ (i,j) $:\n",
        "$ z(i,j) = \\text{activation}\\left( \\sum_m \\sum_n w(m,n) x(i+m, j+n) + b \\right) $\n",
        "Where:\n",
        "- $ x $ is the input (e.g., image pixels)\n",
        "- $ w $ is the convolutional kernel\n",
        "- $ b $ is the bias\n",
        "- $ \\text{activation} $ is typically ReLU\n",
        "\n",
        "Followed by pooling (e.g., max pooling):\n",
        "$ p(i,j) = \\max_{m,n \\in \\text{window}} z(i \\cdot s + m, j \\cdot s + n) $\n",
        "Where $ s $ is the stride.\n",
        "\n",
        "**CNN is a type of Deep Neural Network (DNN)**. A DNN is defined as a neural network with multiple hidden layers, enabling complex feature learning. CNNs typically consist of multiple layers (convolutional, pooling, and fully connected), often numbering in the dozens or hundreds in modern architectures (e.g., VGG, ResNet).\n",
        "\n",
        "A CNN which consists, basically, of:\n",
        "\n",
        "- An input layer (e.g., a 2D image).\n",
        "- A convolutional layer with multiple filters producing feature maps.\n",
        "- A pooling layer reducing spatial dimensions.\n",
        "- A fully connected layer for output (e.g., classification).\n",
        "\n",
        "#### **In the following plot, we'll visualize the following architecture:**\n",
        "\n",
        "##### **1. Input Layer (28×28×1)**\n",
        "- **28×28**: Spatial dimensions of the input image (height × width)\n",
        "- **×1**: Number of channels (grayscale image)\n",
        "- **Example**: MNIST handwritten digits dataset uses 28x28 pixel monochrome images\n",
        "\n",
        "---\n",
        "\n",
        "##### **2. First Convolutional Layer (26×26×32)**\n",
        "- **26×26**: Reduced spatial dimensions after convolution\n",
        "  - Original 28x28 → 26x26 due to 3×3 filter (28 - 3 + 1 = 26)\n",
        "- **×32**: Number of filters/feature maps\n",
        "  - Each filter learns different spatial patterns\n",
        "\n",
        "---\n",
        "\n",
        "##### **3. First Pooling Layer (13×13×32)**\n",
        "- **13×13**: Reduced spatial dimensions after max-pooling\n",
        "  - 2×2 pooling with stride 2 (26/2 = 13)\n",
        "- **×32**: Number of channels preserved\n",
        "  - Pooling operates per channel independently\n",
        "\n",
        "---\n",
        "\n",
        "##### **4. Second Convolutional Layer (11×11×64)**\n",
        "- **11×11**: Spatial dimensions after convolution\n",
        "  - 13 - 3 + 1 = 11 (using 3×3 filters)\n",
        "- **×64**: Increased number of filters\n",
        "  - Deeper layers typically have more filters to capture complex patterns\n",
        "\n",
        "---\n",
        "\n",
        "##### **5. Second Pooling Layer (5×5×64)**\n",
        "- **5×5**: Spatial dimensions after max-pooling\n",
        "  - 11/2 = 5.5 → floor to 5 (common in pooling operations)\n",
        "- **×64**: Number of channels preserved\n",
        "\n",
        "---\n",
        "\n",
        "##### **6. Flatten Layer**\n",
        "- Converts 3D tensor (5×5×64) to 1D vector\n",
        "- **5×5×64 = 1600 units**\n",
        "  - 5 (height) × 5 (width) × 64 (channels) = 1600 elements\n",
        "\n",
        "---\n",
        "\n",
        "##### **7. Fully Connected Layers**\n",
        "| Layer         | Units | Purpose                                                                 |\n",
        "|---------------|-------|-------------------------------------------------------------------------|\n",
        "| **Dense**     | 128   | Learns high-level patterns from flattened features                      |\n",
        "| **Output**    | 10    | Final classification (e.g., 10 digits in MNIST) with softmax activation |\n",
        "\n",
        "---\n",
        "\n",
        "##### **Dimension Reduction Flow**\n",
        "```python\n",
        "Input → Conv → Pool → Conv → Pool → Flatten → Dense → Output\n",
        "28×28×1 → 26×26×32 → 13×13×32 → 11×11×64 → 5×5×64 → 1600 → 128 → 10\n",
        "```\n",
        "\n",
        "##### **Key Operations**\n",
        "1. **Convolution** (Conv2D):\n",
        "   - Filter size: 3×3\n",
        "   - Stride: 1 (no padding → reduces dimensions)\n",
        "   - Activation: ReLU (σ = max(0,x))\n",
        "\n",
        "2. **Max-Pooling**:\n",
        "   - Window size: 2×2\n",
        "   - Stride: 2 (halves spatial dimensions)\n",
        "\n",
        "3. **Flatten**:\n",
        "   - Prepares 3D features for dense layers\n",
        "\n",
        "4. **Fully Connected** (Dense):\n",
        "   - 128 units: Feature compression/abstraction\n",
        "   - 10 units: Final classification (softmax activation)\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "tnOAFvKXb0SG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --------------------------------------------------------------------------\n",
        "# 2. Convolutional Neural Network\n",
        "# --------------------------------------------------------------------------\n",
        "\n",
        "import plotly.graph_objects as go\n",
        "import numpy as np\n",
        "\n",
        "layer_colors = {\n",
        "    'input': '#636EFA',\n",
        "    'conv': '#00CC96',\n",
        "    'pool': '#FFA15A',\n",
        "    'flatten': '#EF553B',\n",
        "    'fc': '#AB63FA',\n",
        "    'output': '#19D3F3',\n",
        "    'activation': '#FF6692'\n",
        "}\n",
        "\n",
        "layer_descriptions = {\n",
        "    'input': \"Input Layer\\n28×28×1 grayscale image\",\n",
        "    'conv': \"Convolutional Layer\\nApplies filters to extract spatial features\",\n",
        "    'pool': \"Pooling Layer\\nReduces spatial dimensions through subsampling\",\n",
        "    'flatten': \"Flatten Layer\\nConverts 3D features to 1D vector\",\n",
        "    'fc': \"Fully Connected Layer\\nLearns global patterns in features\",\n",
        "    'output': \"Output Layer\\nProduces classification probabilities\"\n",
        "}\n",
        "\n",
        "def create_cnn_visualization():\n",
        "    fig = go.Figure()\n",
        "\n",
        "    # Define layer positions\n",
        "    x_positions = [0, 2, 4, 6, 8, 10]\n",
        "    layer_heights = [3, 2.4, 1.8, 1.2, 0.6, 0.3]\n",
        "    layer_depths = [3, 2.4, 1.8, 1.2, 0.6, 0.3]\n",
        "\n",
        "    legend_groups = set()\n",
        "\n",
        "    # Create layers\n",
        "    create_3d_layer(fig, x_positions[0], layer_heights[0], layer_depths[0],\n",
        "                   'input', 'Input\\n28×28×1', legend_groups,\n",
        "                   layer_descriptions['input'])\n",
        "\n",
        "    create_3d_layer(fig, x_positions[1], layer_heights[1], layer_depths[1],\n",
        "                   'conv', 'Conv\\n26×26×32', legend_groups,\n",
        "                   layer_descriptions['conv'], 'ReLU')\n",
        "\n",
        "    create_3d_layer(fig, x_positions[2], layer_heights[2], layer_depths[2],\n",
        "                   'pool', 'Pool\\n13×13×32', legend_groups,\n",
        "                   layer_descriptions['pool'])\n",
        "\n",
        "    create_3d_layer(fig, x_positions[3], layer_heights[3], layer_depths[3],\n",
        "                   'conv', 'Conv\\n11×11×64', legend_groups,\n",
        "                   layer_descriptions['conv'], 'ReLU')\n",
        "\n",
        "    create_3d_layer(fig, x_positions[4], layer_heights[4], layer_depths[4],\n",
        "                   'pool', 'Pool\\n5×5×64', legend_groups,\n",
        "                   layer_descriptions['pool'])\n",
        "\n",
        "    add_flatten_layer(fig, x_positions[5], legend_groups,\n",
        "                     layer_descriptions['flatten'])\n",
        "\n",
        "    add_fc_layers(fig, x_positions[5] + 2, legend_groups)\n",
        "\n",
        "    add_layer_connections(fig, x_positions)\n",
        "\n",
        "    # Configure layout\n",
        "    fig.update_layout(\n",
        "        title=dict(\n",
        "            text=\"Convolutional Neural Network (CNN) Architecture\",\n",
        "            x=0.05,\n",
        "            font=dict(size=24)\n",
        "        ),\n",
        "        template='plotly_white',\n",
        "        margin=dict(l=20, r=300, t=100, b=20),\n",
        "        legend=dict(\n",
        "            title=\"Layer Types\",\n",
        "            x=1.05,\n",
        "            y=0.5,\n",
        "            xanchor='left',\n",
        "            yanchor='middle',\n",
        "            font=dict(size=12)\n",
        "            ),\n",
        "        width=1400,\n",
        "        height=600,\n",
        "        scene=dict(\n",
        "            xaxis=dict(showgrid=False, zeroline=False, visible=False),\n",
        "            yaxis=dict(showgrid=False, zeroline=False, visible=False),\n",
        "            zaxis=dict(showgrid=False, zeroline=False, visible=False),\n",
        "            aspectmode='manual',\n",
        "            aspectratio=dict(x=2, y=1, z=0.5)\n",
        "        ),\n",
        "        annotations=[\n",
        "            dict(\n",
        "                x=1.05,\n",
        "                y=0.9,\n",
        "                xref='paper',\n",
        "                yref='paper',\n",
        "                text=\"<b>CNN Components:</b><br>\"\n",
        "                     \"- Convolution: Feature extraction<br>\"\n",
        "                     \"- Pooling: Dimensionality reduction<br>\"\n",
        "                     \"- Flatten: 3D→1D conversion<br>\"\n",
        "                     \"- Dense: Classification\",\n",
        "                showarrow=False,\n",
        "                align='left',\n",
        "                font=dict(size=14))\n",
        "        ]\n",
        "    )\n",
        "    return fig\n",
        "\n",
        "def create_3d_layer(fig, x_pos, height, depth, layer_type, label_text,\n",
        "                   legend_groups, description, activation=None):\n",
        "    # Create 3D box structure\n",
        "    x = [x_pos, x_pos+1.2, x_pos+1.2, x_pos] * 2\n",
        "    y = [-height/2, -height/2, height/2, height/2] * 2\n",
        "    z = [0]*4 + [depth]*4\n",
        "\n",
        "    # Add all edges with proper legend grouping\n",
        "    edges = [(0,1), (1,2), (2,3), (3,0), (4,5), (5,6), (6,7), (7,4), (0,4), (1,5), (2,6), (3,7)]\n",
        "\n",
        "    for i, (start, end) in enumerate(edges):\n",
        "        show_legend = (layer_type not in legend_groups) and (i == 0)\n",
        "        fig.add_trace(go.Scatter3d(\n",
        "            x=[x[start], x[end]],\n",
        "            y=[y[start], y[end]],\n",
        "            z=[z[start], z[end]],\n",
        "            mode='lines',\n",
        "            line=dict(color=layer_colors[layer_type], width=2),\n",
        "            showlegend=show_legend,\n",
        "            name=layer_descriptions[layer_type].split('\\n')[0],\n",
        "            legendgroup=layer_type,\n",
        "            hoverinfo='text',\n",
        "            hovertext=description\n",
        "        ))\n",
        "    if layer_type not in legend_groups:\n",
        "        legend_groups.add(layer_type)\n",
        "\n",
        "    # Add activation function annotation\n",
        "    if activation:\n",
        "        fig.add_trace(go.Scatter3d(\n",
        "            x=[x_pos+0.6],\n",
        "            y=[height/2 + 0.3],\n",
        "            z=[depth/2],\n",
        "            mode='text',\n",
        "            text=f'σ = {activation}',\n",
        "            textfont=dict(color=layer_colors['activation'], size=14),\n",
        "            showlegend='activation' not in legend_groups,\n",
        "            name='Activation Function',\n",
        "            legendgroup='activation',\n",
        "            hoverinfo='text',\n",
        "            hovertext=f\"Non-linear activation function<br>({activation})\"\n",
        "        ))\n",
        "        if 'activation' not in legend_groups:\n",
        "            legend_groups.add('activation')\n",
        "\n",
        "    # Add layer label\n",
        "    fig.add_trace(go.Scatter3d(\n",
        "        x=[x_pos+0.6],\n",
        "        y=[-height/2 - 0.5],\n",
        "        z=[0],\n",
        "        mode='text',\n",
        "        text=label_text,\n",
        "        textfont=dict(color='black', size=14),\n",
        "        hoverinfo='none',\n",
        "        showlegend=False\n",
        "    ))\n",
        "\n",
        "def add_flatten_layer(fig, x_pos, legend_groups, description):\n",
        "    y_values = np.linspace(-1, 1, 20)\n",
        "    fig.add_trace(go.Scatter3d(\n",
        "        x=[x_pos]*20,\n",
        "        y=y_values,\n",
        "        z=[0]*20,\n",
        "        mode='lines',\n",
        "        line=dict(color=layer_colors['flatten'], width=6),\n",
        "        showlegend='flatten' not in legend_groups,\n",
        "        name=layer_descriptions['flatten'].split('\\n')[0],\n",
        "        legendgroup='flatten',\n",
        "        hoverinfo='text',\n",
        "        hovertext=description\n",
        "    ))\n",
        "    legend_groups.add('flatten')\n",
        "\n",
        "def add_fc_layers(fig, x_pos, legend_groups):\n",
        "    fc_layers = [\n",
        "        {'units': 128, 'label': 'Dense\\n128', 'activation': 'ReLU'},\n",
        "        {'units': 10, 'label': 'Output\\n10', 'activation': 'Softmax'}\n",
        "    ]\n",
        "\n",
        "    for i, layer in enumerate(fc_layers):\n",
        "        layer_type = 'output' if i == len(fc_layers)-1 else 'fc'\n",
        "        x = x_pos + i*2\n",
        "\n",
        "        # Add nodes\n",
        "        y_values = np.linspace(-0.8, 0.8, layer['units'])\n",
        "        fig.add_trace(go.Scatter3d(\n",
        "            x=[x]*len(y_values),\n",
        "            y=y_values,\n",
        "            z=[0]*len(y_values),\n",
        "            mode='markers',\n",
        "            marker=dict(size=6, color=layer_colors[layer_type]),\n",
        "            showlegend=layer_type not in legend_groups,\n",
        "            name=layer_descriptions[layer_type].split('\\n')[0],\n",
        "            legendgroup=layer_type,\n",
        "            hoverinfo='text',\n",
        "            hovertext=layer_descriptions[layer_type]\n",
        "        ))\n",
        "        if layer_type not in legend_groups:\n",
        "            legend_groups.add(layer_type)\n",
        "\n",
        "        # Add activation annotation\n",
        "        fig.add_trace(go.Scatter3d(\n",
        "            x=[x + 0.3],\n",
        "            y=[0.9],\n",
        "            z=[0],\n",
        "            mode='text',\n",
        "            text=f'σ = {layer[\"activation\"]}',\n",
        "            textfont=dict(color=layer_colors['activation'], size=14),\n",
        "            showlegend=False\n",
        "        ))\n",
        "\n",
        "        # Add layer label\n",
        "        fig.add_trace(go.Scatter3d(\n",
        "            x=[x],\n",
        "            y=[-1.2],\n",
        "            z=[0],\n",
        "            mode='text',\n",
        "            text=layer['label'],\n",
        "            textfont=dict(color='black', size=14),\n",
        "            showlegend=False\n",
        "        ))\n",
        "\n",
        "def add_layer_connections(fig, x_positions):\n",
        "    operations = [\n",
        "        (\"Conv2D\", \"3×3 kernel, 32 filters\", \"Stride 1, ReLU\"),\n",
        "        (\"MaxPool\", \"2×2 window\", \"Stride 2\"),\n",
        "        (\"Conv2D\", \"3×3 kernel, 64 filters\", \"Stride 1, ReLU\"),\n",
        "        (\"MaxPool\", \"2×2 window\", \"Stride 2\"),\n",
        "        (\"Flatten\", \"3D→1D conversion\", \"1600 → 128\"),\n",
        "        (\"Dense\", \"Fully connected\", \"128 → 10\")\n",
        "    ]\n",
        "\n",
        "    for i in range(len(x_positions)-1):\n",
        "        x_start = x_positions[i] + 1.2\n",
        "        x_end = x_positions[i+1]\n",
        "\n",
        "        # Add connection line\n",
        "        fig.add_trace(go.Scatter3d(\n",
        "            x=np.linspace(x_start, x_end, 30),\n",
        "            y=np.zeros(30),\n",
        "            z=np.zeros(30),\n",
        "            mode='lines',\n",
        "            line=dict(color='gray', width=1),\n",
        "            hoverinfo='text',\n",
        "            hovertext=f\"Operation: {operations[i][0]}<br>{operations[i][1]}<br>{operations[i][2]}\",\n",
        "            showlegend=False\n",
        "        ))\n",
        "\n",
        "        # Add operation label\n",
        "        fig.add_trace(go.Scatter3d(\n",
        "            x=[(x_start + x_end)/2],\n",
        "            y=[0.5],\n",
        "            z=[0],\n",
        "            mode='text',\n",
        "            text=operations[i][0],\n",
        "            textfont=dict(size=12, color='black'),\n",
        "            showlegend=False\n",
        "        ))\n",
        "\n",
        "# Generate and display the visualization\n",
        "fig = create_cnn_visualization()\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "j3OylZdzb66E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Implementation of a CNN**\n",
        "\n",
        "Convolutional Neural Network (CNN)\n",
        "\n",
        "CNNs excel at image tasks by extracting spatial features. Let's use it on MNIST too."
      ],
      "metadata": {
        "id": "KWg_VUqccPt8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install Pytorch (if not installed) with libraries to handle vision/image operations (Torchvision) and get metrics (Torchmetrics)\n",
        "!pip install torch torchvision torchmetrics"
      ],
      "metadata": {
        "id": "ifxMXTLwdBxD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "from torchmetrics import Accuracy\n",
        "from tqdm import tqdm\n",
        "import plotly.graph_objects as go\n",
        "\n",
        "# Define the CNN model\n",
        "class CNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, padding=1)\n",
        "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.fc1 = nn.Linear(64 * 7 * 7, 128)\n",
        "        self.fc2 = nn.Linear(128, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(torch.relu(self.conv1(x)))\n",
        "        x = self.pool(torch.relu(self.conv2(x)))\n",
        "        x = x.view(-1, 64 * 7 * 7)\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "# Data loading\n",
        "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
        "train_dataset = datasets.MNIST(root='./data', train=True, transform=transform, download=True)\n",
        "train_set, val_set = random_split(train_dataset, [55000, 5000])  # 55k train, 5k val\n",
        "train_loader = DataLoader(train_set, batch_size=64, shuffle=True)\n",
        "val_loader = DataLoader(val_set, batch_size=64, shuffle=False)\n",
        "test_dataset = datasets.MNIST(root='./data', train=False, transform=transform)\n",
        "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
        "\n",
        "# Training setup\n",
        "model = CNN()\n",
        "# model = model.to(device)  # Move model to GPU if available\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "accuracy = Accuracy(task=\"multiclass\", num_classes=10)\n",
        "\n",
        "# Lists to store losses\n",
        "train_losses = []\n",
        "val_losses = []\n",
        "\n",
        "num_epochs = 5\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    train_loss = 0.0\n",
        "    for images, labels in tqdm(train_loader, desc=f'Epoch {epoch+1}/{num_epochs}'):\n",
        "        # images, labels = images.to(device), labels.to(device)  # Move data to GPU\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        train_loss += loss.item()\n",
        "    train_losses.append(train_loss / len(train_loader))\n",
        "\n",
        "    # Validation\n",
        "    model.eval()\n",
        "    val_loss = 0.0\n",
        "    with torch.no_grad():\n",
        "        for images, labels in val_loader:\n",
        "            # images, labels = images.to(device), labels.to(device)  # Move data to GPU\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            val_loss += loss.item()\n",
        "            accuracy.update(outputs, labels)\n",
        "    val_losses.append(val_loss / len(val_loader))\n",
        "    val_acc = accuracy.compute()\n",
        "    print(f'Epoch {epoch+1}, Train Loss: {train_losses[-1]:.4f}, Val Loss: {val_losses[-1]:.4f}, Val Accuracy: {val_acc:.2f}')\n",
        "    accuracy.reset()\n",
        "\n",
        "# Test set evaluation\n",
        "model.eval()\n",
        "test_loss = 0.0\n",
        "test_acc = 0.0\n",
        "with torch.no_grad():\n",
        "    for images, labels in test_loader:\n",
        "        # images, labels = images.to(device), labels.to(device)\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        test_loss += loss.item()\n",
        "        accuracy.update(outputs, labels)\n",
        "    test_loss /= len(test_loader)\n",
        "    test_acc = accuracy.compute()\n",
        "    print(f'Test Loss: {test_loss:.4f}, Test Accuracy: {test_acc:.2f}')\n",
        "\n",
        "# Plot losses using Plotly\n",
        "fig = go.Figure()\n",
        "fig.add_trace(go.Scatter(\n",
        "    x=list(range(1, len(train_losses)+1)),\n",
        "    y=train_losses,\n",
        "    mode='lines+markers',\n",
        "    name='Train Loss',\n",
        "    line=dict(color='blue', width=2)\n",
        "))\n",
        "\n",
        "fig.add_trace(go.Scatter(\n",
        "    x=list(range(1, len(val_losses)+1)),\n",
        "    y=val_losses,\n",
        "    mode='lines+markers',\n",
        "    name='Validation Loss',\n",
        "    line=dict(color='red', width=2)\n",
        "))\n",
        "\n",
        "fig.update_layout(\n",
        "    title='CNN Training Progress',\n",
        "    xaxis_title='Epoch',\n",
        "    yaxis_title='Loss',\n",
        "    template='plotly_white',\n",
        "    legend=dict(x=0.8, y=0.9, bgcolor='rgba(255,255,255,0.5)'),\n",
        "    margin=dict(l=40, r=20, t=40, b=20),\n",
        "    hovermode='x unified'\n",
        ")\n",
        "\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "glUARINpc0Bc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import plotly.subplots as sp\n",
        "import numpy as np\n",
        "\n",
        "# Collect predictions from the test set\n",
        "model.eval()\n",
        "images_list = []\n",
        "true_labels = []\n",
        "pred_labels = []\n",
        "correctness = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, labels in test_loader:\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        images_list.append(images.cpu().numpy())\n",
        "        true_labels.append(labels.cpu().numpy())\n",
        "        pred_labels.append(predicted.cpu().numpy())\n",
        "        correctness.append(predicted == labels)\n",
        "\n",
        "# Concatenate all batches\n",
        "images_list = np.concatenate(images_list, axis=0)\n",
        "true_labels = np.concatenate(true_labels, axis=0)\n",
        "pred_labels = np.concatenate(pred_labels, axis=0)\n",
        "correctness = np.concatenate(correctness, axis=0)\n",
        "\n",
        "# Select a subset to display (e.g., 25 images)\n",
        "num_display = 25\n",
        "indices = np.random.choice(len(images_list), num_display, replace=False)\n",
        "selected_images = images_list[indices]\n",
        "selected_true = true_labels[indices]\n",
        "selected_pred = pred_labels[indices]\n",
        "selected_correct = correctness[indices]\n",
        "\n",
        "# Create a subplot grid\n",
        "rows, cols = 5, 5\n",
        "fig = sp.make_subplots(rows=rows, cols=cols, subplot_titles=[f\"True: {t}, Pred: {p}\" for t, p in zip(selected_true, selected_pred)])\n",
        "\n",
        "for i in range(num_display):\n",
        "    row = i // cols + 1\n",
        "    col = i % cols + 1\n",
        "    img = selected_images[i].squeeze()  # Remove channel dimension\n",
        "    img = (img * 0.5 + 0.5)  # Denormalize to [0, 1]\n",
        "    img = np.flipud(img)  # Flip vertically to correct orientation\n",
        "\n",
        "    # Add image to subplot\n",
        "    fig.add_trace(\n",
        "        go.Heatmap(z=img, colorscale='gray', showscale=False),\n",
        "        row=row, col=col\n",
        "    )\n",
        "\n",
        "    # Update title color based on correctness\n",
        "    title_color = 'green' if selected_correct[i] else 'red'\n",
        "    fig.layout.annotations[i].update(font=dict(color=title_color))\n",
        "\n",
        "# Update layout\n",
        "fig.update_layout(\n",
        "    title_text=\"CNN MNIST Classification Results (Green: Correct, Red: Incorrect)\",\n",
        "    height=800,\n",
        "    width=800,\n",
        "    showlegend=False\n",
        ")\n",
        "\n",
        "# Remove axes for cleaner visualization\n",
        "for i in range(1, num_display + 1):\n",
        "    fig.update_xaxes(showticklabels=False, showgrid=False, zeroline=False, row=(i-1)//cols+1, col=(i-1)%cols+1)\n",
        "    fig.update_yaxes(showticklabels=False, showgrid=False, zeroline=False, row=(i-1)//cols+1, col=(i-1)%cols+1)\n",
        "\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "uOayWqo9c6w6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Exercise**: Adjust the kernel size (e.g., from 3 to 5) and observe the impact."
      ],
      "metadata": {
        "id": "lfQxW75fdOil"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Extending CNN with Transfer Learning**\n",
        "\n",
        "### **Now, let's work with Transfer Learning**\n",
        "\n",
        "</br>\n",
        "\n",
        "##### **Transfer Learning with ResNet18**\n",
        "\n",
        "\n",
        "> Transfer learning uses pre-trained models like ResNet18 for new tasks. We'll fine-tune it on CIFAR-10.\n",
        "\n",
        "*Fine-tuning a model* involves taking a pre-trained model with learned weights and further training it on a new, often smaller dataset specific to a target task. This process adapts the weights to better fit the new data [1], starting from a more informed initialization than random weights."
      ],
      "metadata": {
        "id": "CjNvgU1LdewK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import plotly.subplots as sp\n",
        "import numpy as np\n",
        "\n",
        "def plot_prediction():\n",
        "    # CIFAR-10 class names\n",
        "    class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
        "\n",
        "    # Collect predictions from the test set\n",
        "    model.eval()\n",
        "    images_list = []\n",
        "    true_labels = []\n",
        "    pred_labels = []\n",
        "    correctness = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, labels in test_loader:\n",
        "            outputs = model(images)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            images_list.append(images.cpu().numpy())\n",
        "            true_labels.append(labels.cpu().numpy())\n",
        "            pred_labels.append(predicted.cpu().numpy())\n",
        "            correctness.append(predicted == labels)\n",
        "\n",
        "    # Concatenate all batches\n",
        "    images_list = np.concatenate(images_list, axis=0)\n",
        "    true_labels = np.concatenate(true_labels, axis=0)\n",
        "    pred_labels = np.concatenate(pred_labels, axis=0)\n",
        "    correctness = np.concatenate(correctness, axis=0)\n",
        "\n",
        "    # Select a subset to display (e.g., 25 images)\n",
        "    num_display = 25\n",
        "    indices = np.random.choice(len(images_list), num_display, replace=False)\n",
        "    selected_images = images_list[indices]\n",
        "    selected_true = true_labels[indices]\n",
        "    selected_pred = pred_labels[indices]\n",
        "    selected_correct = correctness[indices]\n",
        "\n",
        "    # Create a subplot grid\n",
        "    rows, cols = 5, 5\n",
        "    fig = sp.make_subplots(\n",
        "        rows=rows, cols=cols,\n",
        "        subplot_titles=[f\"True: {class_names[t]}, Pred: {class_names[p]}\" for t, p in zip(selected_true, selected_pred)]\n",
        "    )\n",
        "\n",
        "    for i in range(num_display):\n",
        "        row = i // cols + 1\n",
        "        col = i % cols + 1\n",
        "        img = selected_images[i]  # Shape: (3, 64, 64)\n",
        "        img = (img * 0.5 + 0.5)  # Denormalize to [0, 1]\n",
        "        img = np.transpose(img, (1, 2, 0))  # Change to (64, 64, 3) for Plotly\n",
        "        img = np.clip(img, 0, 1) * 255  # Scale to [0, 255] and clip\n",
        "        img = img.astype(np.uint8)\n",
        "\n",
        "        # Add image to subplot\n",
        "        fig.add_trace(\n",
        "            go.Image(z=img, hoverinfo='none'),\n",
        "            row=row, col=col\n",
        "        )\n",
        "\n",
        "        # Update title color based on correctness\n",
        "        title_color = 'green' if selected_correct[i] else 'red'\n",
        "        fig.layout.annotations[i].update(font=dict(color=title_color))\n",
        "\n",
        "    # Update layout\n",
        "    fig.update_layout(\n",
        "        title_text=\"CIFAR-10 Classification Results (Green: Correct, Red: Incorrect)\",\n",
        "        height=800,\n",
        "        width=1200,\n",
        "        showlegend=False,\n",
        "        margin=dict(l=10, r=20, t=60, b=20)\n",
        "    )\n",
        "\n",
        "    # Remove axes for cleaner visualization\n",
        "    for i in range(1, num_display + 1):\n",
        "        fig.update_xaxes(showticklabels=False, showgrid=False, zeroline=False, row=(i-1)//cols+1, col=(i-1)%cols+1)\n",
        "        fig.update_yaxes(showticklabels=False, showgrid=False, zeroline=False, row=(i-1)//cols+1, col=(i-1)%cols+1)\n",
        "\n",
        "    fig.show()"
      ],
      "metadata": {
        "id": "vi34l3HpePV0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Before that, let's train a model without any wights, and then, compare to another implementation, using the weights from ImageNet."
      ],
      "metadata": {
        "id": "Oz4H7uMHedSD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Without ImageNet weights ------------------------------------\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torchvision.models import resnet50\n",
        "from torch.utils.data import DataLoader, Subset, random_split\n",
        "from torchmetrics import Accuracy\n",
        "from tqdm import tqdm\n",
        "import plotly.graph_objects as go\n",
        "import numpy as np\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "torch.manual_seed(42)\n",
        "\n",
        "# Device configuration\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Load ResNet50 without pretrained weights\n",
        "model = resnet50(weights=None)\n",
        "model = model.to(device)\n",
        "\n",
        "num_ftrs = model.fc.in_features\n",
        "model.fc = nn.Linear(num_ftrs, 10)\n",
        "\n",
        "# Data loading for CIFAR-10\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize(64),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "])\n",
        "\n",
        "# Load full training and test datasets\n",
        "train_full = datasets.CIFAR10(root='./data', train=True, transform=transform, download=True)\n",
        "test_full = datasets.CIFAR10(root='./data', train=False, transform=transform, download=True)\n",
        "\n",
        "# Select 6,000 random indices for training and validation\n",
        "indices = torch.randperm(len(train_full))[:6000]\n",
        "train_subset = Subset(train_full, indices)\n",
        "\n",
        "# Split the subset into training (5,000) and validation (1,000) sets\n",
        "train_set, val_set = random_split(train_subset, [5000, 1000])\n",
        "\n",
        "# Select 1,000 random indices for the test set\n",
        "test_indices = torch.randperm(len(test_full))[:1000]\n",
        "test_set = Subset(test_full, test_indices)\n",
        "\n",
        "# Create data loaders\n",
        "train_loader = DataLoader(train_set, batch_size=128, shuffle=True, num_workers=2)\n",
        "val_loader = DataLoader(val_set, batch_size=128, shuffle=False, num_workers=2)\n",
        "test_loader = DataLoader(test_set, batch_size=128, shuffle=False, num_workers=2)  # Fixed: test_set instead of test_dataset\n",
        "\n",
        "# Training setup\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "# Train the entire model since we're starting from scratch (no pretrained weights)\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "accuracy = Accuracy(task=\"multiclass\", num_classes=10).to(device)\n",
        "\n",
        "# Lists to store metrics\n",
        "train_losses = []\n",
        "val_losses = []\n",
        "val_accuracies = []\n",
        "\n",
        "num_epochs = 2\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(num_epochs):\n",
        "    # Training phase\n",
        "    model.train()\n",
        "    train_loss = 0.0\n",
        "\n",
        "    for images, labels in tqdm(train_loader, desc=f'Epoch {epoch+1}/{num_epochs}'):\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_loss += loss.item()\n",
        "\n",
        "    train_losses.append(train_loss / len(train_loader))\n",
        "\n",
        "    # Validation phase\n",
        "    model.eval()\n",
        "    val_loss = 0.0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, labels in val_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            val_loss += loss.item()\n",
        "            accuracy.update(outputs, labels)\n",
        "\n",
        "    val_losses.append(val_loss / len(val_loader))\n",
        "    val_acc = accuracy.compute()\n",
        "    val_accuracies.append(val_acc.item())\n",
        "\n",
        "    print(f'Epoch {epoch+1}, Train Loss: {train_losses[-1]:.4f}, Val Loss: {val_losses[-1]:.4f}, Val Accuracy: {val_acc:.4f}')\n",
        "    accuracy.reset()\n",
        "\n",
        "# Test set evaluation (final performance metric)\n",
        "print(\"\\n===== Final Model Evaluation on Test Set =====\")\n",
        "model.eval()\n",
        "test_loss = 0.0\n",
        "accuracy.reset()\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, labels in tqdm(test_loader, desc='Evaluating on test set'):\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        test_loss += loss.item()\n",
        "        accuracy.update(outputs, labels)\n",
        "\n",
        "    test_loss /= len(test_loader)\n",
        "    test_acc = accuracy.compute()\n",
        "    print(f'Final Test Loss: {test_loss:.4f}')\n",
        "    print(f'Final Test Accuracy: {test_acc:.4f}')\n",
        "    print(\"===========================================================\")\n",
        "    print(f\"Model performance: {test_acc*100:.2f}% accuracy on unseen test data\")\n",
        "\n",
        "# Create two separate plots for better clarity\n",
        "\n",
        "# Plot 1: Training and Validation Loss\n",
        "loss_fig = go.Figure()\n",
        "\n",
        "loss_fig.add_trace(go.Scatter(\n",
        "    x=list(range(1, len(train_losses)+1)),\n",
        "    y=train_losses,\n",
        "    mode='lines+markers',\n",
        "    name='Training Loss',\n",
        "    line=dict(color='blue', width=2),\n",
        "    marker=dict(size=8)\n",
        "))\n",
        "\n",
        "loss_fig.add_trace(go.Scatter(\n",
        "    x=list(range(1, len(val_losses)+1)),\n",
        "    y=val_losses,\n",
        "    mode='lines+markers',\n",
        "    name='Validation Loss',\n",
        "    line=dict(color='red', width=2),\n",
        "    marker=dict(size=8)\n",
        "))\n",
        "\n",
        "loss_fig.update_layout(\n",
        "    title='Training and Validation Loss (ResNet50 without ImageNet Weights)',\n",
        "    xaxis_title='Epoch',\n",
        "    yaxis_title='Loss',\n",
        "    template='plotly_white',\n",
        "    legend=dict(x=0.01, y=0.99),\n",
        "    margin=dict(l=40, r=40, t=60, b=40),\n",
        "    hovermode='x unified',\n",
        "    xaxis=dict(tickmode='linear', dtick=1)\n",
        ")\n",
        "\n",
        "# Plot 2: Validation Accuracy (during training)\n",
        "acc_fig = go.Figure()\n",
        "\n",
        "acc_fig.add_trace(go.Scatter(\n",
        "    x=list(range(1, len(val_accuracies)+1)),\n",
        "    y=val_accuracies,\n",
        "    mode='lines+markers',\n",
        "    name='Validation Accuracy',\n",
        "    line=dict(color='green', width=2),\n",
        "    marker=dict(size=8)\n",
        "))\n",
        "\n",
        "acc_fig.update_layout(\n",
        "    title='Validation Accuracy During Training (ResNet50 without ImageNet Weights)',\n",
        "    xaxis_title='Epoch',\n",
        "    yaxis_title='Accuracy',\n",
        "    template='plotly_white',\n",
        "    yaxis=dict(range=[0, 1]),\n",
        "    legend=dict(x=0.01, y=0.01),\n",
        "    margin=dict(l=40, r=40, t=60, b=40),\n",
        "    hovermode='x unified',\n",
        "    xaxis=dict(tickmode='linear', dtick=1)\n",
        ")\n",
        "\n",
        "# Display both plots\n",
        "loss_fig.show()\n",
        "acc_fig.show()\n",
        "\n",
        "# After test evaluation, add test accuracy to a final comparison plot\n",
        "final_fig = go.Figure()\n",
        "\n",
        "final_fig.add_trace(go.Bar(\n",
        "    x=['Training', 'Validation', 'Test'],\n",
        "    y=[train_losses[-1], val_losses[-1], test_loss],\n",
        "    name='Final Loss',\n",
        "    marker_color=['blue', 'red', 'purple']\n",
        "))\n",
        "\n",
        "# Add another trace for accuracy (only validation and test have accuracy)\n",
        "final_fig.add_trace(go.Bar(\n",
        "    x=['Training', 'Validation', 'Test'],\n",
        "    y=[None, val_accuracies[-1], test_acc.item()],\n",
        "    name='Final Accuracy',\n",
        "    marker_color=['lightblue', 'lightgreen', 'green'],\n",
        "    yaxis='y2'\n",
        "))\n",
        "\n",
        "# final_fig.update_layout(\n",
        "#     title='Final Model Performance (ResNet50 without ImageNet Weights)',\n",
        "#     template='plotly_white',\n",
        "#     yaxis=dict(\n",
        "#         title='Loss',\n",
        "#         side='left'\n",
        "#     ),\n",
        "#     yaxis2=dict(\n",
        "#         title='Accuracy',\n",
        "#         overlaying='y',\n",
        "#         side='right',\n",
        "#         range=[0, 1]\n",
        "#     ),\n",
        "#     barmode='group',\n",
        "#     legend=dict(x=0.01, y=0.99),\n",
        "#     margin=dict(l=40, r=40, t=60, b=40)\n",
        "# )\n",
        "\n",
        "final_fig.show()\n",
        "\n",
        "# Save the model\n",
        "# torch.save(model.state_dict(), 'resnet50_cifar10_no_pretrained.pth')\n",
        "# print(\"Model saved to resnet50_cifar10_no_pretrained.pth\")"
      ],
      "metadata": {
        "id": "pH7OsgQGk_e8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot results\n",
        "plot_prediction()"
      ],
      "metadata": {
        "id": "Z5ujXl8ue1su"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, let's train the model using the weights from ImageNet."
      ],
      "metadata": {
        "id": "sduHFrlFe8CO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# With ImageNet weights ------------------------------------\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torchvision.models import resnet18\n",
        "from torch.utils.data import DataLoader, Subset, random_split\n",
        "from torchmetrics import Accuracy\n",
        "from tqdm import tqdm\n",
        "import plotly.graph_objects as go\n",
        "import numpy as np\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "torch.manual_seed(42)\n",
        "\n",
        "# Set device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Load pre-trained ResNet18\n",
        "model = resnet18(weights='DEFAULT')\n",
        "model = model.to(device)\n",
        "\n",
        "# ResNet18 expects 3 channels (RGB images)\n",
        "num_ftrs = model.fc.in_features\n",
        "model.fc = nn.Linear(num_ftrs, 10)\n",
        "\n",
        "# Data transformation\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize(64),  # Resize images to 64x64\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "])\n",
        "\n",
        "# Load full training and test datasets\n",
        "train_full = datasets.CIFAR10(root='./data', train=True, transform=transform, download=True)\n",
        "test_full = datasets.CIFAR10(root='./data', train=False, transform=transform, download=True)\n",
        "\n",
        "# Select 6,000 random indices for training and validation\n",
        "indices = torch.randperm(len(train_full))[:6000]\n",
        "train_subset = Subset(train_full, indices)\n",
        "\n",
        "# Split the subset into training (5,000) and validation (1,000) sets\n",
        "train_set, val_set = random_split(train_subset, [5000, 1000])\n",
        "\n",
        "# Select 1,000 random indices for the test set\n",
        "test_indices = torch.randperm(len(test_full))[:1000]\n",
        "test_set = Subset(test_full, test_indices)\n",
        "\n",
        "# Create data loaders\n",
        "train_loader = DataLoader(train_set, batch_size=128, shuffle=True, num_workers=2)\n",
        "val_loader = DataLoader(val_set, batch_size=128, shuffle=False, num_workers=2)\n",
        "test_loader = DataLoader(test_set, batch_size=128, shuffle=False, num_workers=2)  # Fixed: test_set instead of test_dataset\n",
        "\n",
        "# Training setup\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.fc.parameters(), lr=0.001)  # Optimize only fc layer\n",
        "accuracy = Accuracy(task=\"multiclass\", num_classes=10).to(device)\n",
        "\n",
        "# Lists to store losses and accuracies\n",
        "train_losses = []\n",
        "val_losses = []\n",
        "val_accuracies = []\n",
        "\n",
        "num_epochs = 2\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(num_epochs):\n",
        "    # Training phase\n",
        "    model.train()\n",
        "    train_loss = 0.0\n",
        "\n",
        "    for images, labels in tqdm(train_loader, desc=f'Epoch {epoch+1}/{num_epochs}'):\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_loss += loss.item()\n",
        "\n",
        "    train_losses.append(train_loss / len(train_loader))\n",
        "\n",
        "    # Validation phase\n",
        "    model.eval()\n",
        "    val_loss = 0.0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, labels in val_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            val_loss += loss.item()\n",
        "            accuracy.update(outputs, labels)\n",
        "\n",
        "    val_losses.append(val_loss / len(val_loader))\n",
        "    val_acc = accuracy.compute()\n",
        "    val_accuracies.append(val_acc.item())\n",
        "\n",
        "    print(f'Epoch {epoch+1}, Train Loss: {train_losses[-1]:.4f}, Val Loss: {val_losses[-1]:.4f}, Val Accuracy: {val_acc:.4f}')\n",
        "    accuracy.reset()\n",
        "\n",
        "# Test set evaluation (final performance metric)\n",
        "print(\"\\n===== Final Model Evaluation on Test Set =====\")\n",
        "model.eval()\n",
        "test_loss = 0.0\n",
        "accuracy.reset()\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, labels in tqdm(test_loader, desc='Evaluating on test set'):\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        test_loss += loss.item()\n",
        "        accuracy.update(outputs, labels)\n",
        "\n",
        "    test_loss /= len(test_loader)\n",
        "    test_acc = accuracy.compute()\n",
        "    print(f'Final Test Loss: {test_loss:.4f}')\n",
        "    print(f'Final Test Accuracy: {test_acc:.4f}')\n",
        "    print(\"===========================================================\")\n",
        "    print(f\"Model performance: {test_acc*100:.2f}% accuracy on unseen test data\")\n",
        "\n",
        "# Create two separate plots for better clarity\n",
        "\n",
        "# Plot 1: Training and Validation Loss\n",
        "loss_fig = go.Figure()\n",
        "\n",
        "loss_fig.add_trace(go.Scatter(\n",
        "    x=list(range(1, len(train_losses)+1)),\n",
        "    y=train_losses,\n",
        "    mode='lines+markers',\n",
        "    name='Training Loss',\n",
        "    line=dict(color='blue', width=2),\n",
        "    marker=dict(size=8)\n",
        "))\n",
        "\n",
        "loss_fig.add_trace(go.Scatter(\n",
        "    x=list(range(1, len(val_losses)+1)),\n",
        "    y=val_losses,\n",
        "    mode='lines+markers',\n",
        "    name='Validation Loss',\n",
        "    line=dict(color='red', width=2),\n",
        "    marker=dict(size=8)\n",
        "))\n",
        "\n",
        "loss_fig.update_layout(\n",
        "    title='Training and Validation Loss',\n",
        "    xaxis_title='Epoch',\n",
        "    yaxis_title='Loss',\n",
        "    template='plotly_white',\n",
        "    legend=dict(x=0.01, y=0.99),\n",
        "    margin=dict(l=40, r=40, t=60, b=40),\n",
        "    hovermode='x unified',\n",
        "    xaxis=dict(tickmode='linear', dtick=1)\n",
        ")\n",
        "\n",
        "# Plot 2: Validation Accuracy (during training)\n",
        "acc_fig = go.Figure()\n",
        "\n",
        "acc_fig.add_trace(go.Scatter(\n",
        "    x=list(range(1, len(val_accuracies)+1)),\n",
        "    y=val_accuracies,\n",
        "    mode='lines+markers',\n",
        "    name='Validation Accuracy',\n",
        "    line=dict(color='green', width=2),\n",
        "    marker=dict(size=8)\n",
        "))\n",
        "\n",
        "acc_fig.update_layout(\n",
        "    title='Validation Accuracy During Training',\n",
        "    xaxis_title='Epoch',\n",
        "    yaxis_title='Accuracy',\n",
        "    template='plotly_white',\n",
        "    yaxis=dict(range=[0, 1]),\n",
        "    legend=dict(x=0.01, y=0.01),\n",
        "    margin=dict(l=40, r=40, t=60, b=40),\n",
        "    hovermode='x unified',\n",
        "    xaxis=dict(tickmode='linear', dtick=1)\n",
        ")\n",
        "\n",
        "# Display both plots\n",
        "loss_fig.show()\n",
        "acc_fig.show()\n",
        "\n",
        "# After test evaluation, add test accuracy to a final comparison plot\n",
        "final_fig = go.Figure()\n",
        "\n",
        "final_fig.add_trace(go.Bar(\n",
        "    x=['Training', 'Validation', 'Test'],\n",
        "    y=[train_losses[-1], val_losses[-1], test_loss],\n",
        "    name='Final Loss',\n",
        "    marker_color=['blue', 'red', 'purple']\n",
        "))\n",
        "\n",
        "# Add another trace for accuracy (only validation and test have accuracy)\n",
        "final_fig.add_trace(go.Bar(\n",
        "    x=['Training', 'Validation', 'Test'],\n",
        "    y=[None, val_accuracies[-1], test_acc.item()],\n",
        "    name='Final Accuracy',\n",
        "    marker_color=['lightblue', 'lightgreen', 'green'],\n",
        "    yaxis='y2'\n",
        "))\n",
        "\n",
        "# final_fig.update_layout(\n",
        "#     title='Final Model Performance',\n",
        "#     template='plotly_white',\n",
        "#     yaxis=dict(\n",
        "#         title='Loss',\n",
        "#         side='left'\n",
        "#     ),\n",
        "#     yaxis2=dict(\n",
        "#         title='Accuracy',\n",
        "#         overlaying='y',\n",
        "#         side='right',\n",
        "#         range=[0, 1]\n",
        "#     ),\n",
        "#     barmode='group',\n",
        "#     legend=dict(x=0.01, y=0.99),\n",
        "#     margin=dict(l=40, r=40, t=60, b=40)\n",
        "# )\n",
        "\n",
        "final_fig.show()\n",
        "\n",
        "# Save the model\n",
        "# torch.save(model.state_dict(), 'resnet18_cifar10.pth')\n",
        "# print(\"Model saved to resnet18_cifar10.pth\")"
      ],
      "metadata": {
        "id": "CvHbw1Z_mcfp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot results\n",
        "plot_prediction()"
      ],
      "metadata": {
        "id": "kbCzapGzftRd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **REFERENCES**\n",
        "\n",
        "**This hands-on was based or inspired on the following reference materials:**\n",
        "\n",
        "- Deep Learning with PyTorch by Manning Publications [1]\n",
        "- PyTorch Official Documentation [2]\n",
        "- PyTorch Tutorials [3]\n",
        "- Learn PyTorch for Deep Learning: Zero to Mastery [4]\n",
        "\n",
        "\n",
        "[1] Stevens, E., Antiga, L., & Viehmann, T. (2020). Deep Learning with PyTorch: Build, train, and tune neural networks using Python tools. Manning.\n",
        "\n",
        "[2] PyTorch (2025). PyTorch documentation. The Linux Foundation. https://docs.pytorch.org/docs/stable/index.html\n",
        "\n",
        "[3] PyTorch (2024). Welcome to PyTorch Tutorials. The Linux Foundation. https://docs.pytorch.org/tutorials/\n",
        "\n",
        "[4] Learn Pytorch (2023). Learn PyTorch for Deep Learning: Zero to Mastery. By Daniel Bourke. https://www.learnpytorch.io/\n",
        "\n",
        "[5] Project Gutenberg (2025). Alice's Adventures in Wonderland, by Lewis Carroll. https://www.gutenberg.org/files/11/11-0.txt"
      ],
      "metadata": {
        "id": "VehbjncJf1t5"
      }
    }
  ]
}