{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### **State University of Campinas - UNICAMP** </br>\n",
        "**Course**: MC886A </br>\n",
        "**Professor**: Marcelo da Silva Reis </br>\n",
        "**TA (PED)**: Marcos Vinicius Souza Freire\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "59D5zcEKMtYA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Hands-On: Deep Learnng with PyTorch**\n",
        "##### Notebook: 00 Perceptron and MLP\n",
        "---"
      ],
      "metadata": {
        "id": "Km72bjk-MxLq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Table of Contents**\n",
        "\n",
        "1. [**Objectives**](#objectives) </br>\n",
        "2. [**Prerequisites**](#prerequisites) </br>\n",
        "3. [**Basic Concept**](#basic-concept) </br>\n",
        "  3.1. [Perceptron](#1-perceptron) </br>\n",
        "  3.2. [Single-Layer Perceptron (SLP)](#2-single--layer-perceptron-slp) </br>\n",
        "  3.3. [Multi-Layer Perceptron (MLP)](#3-multi--layer-perceptron-mlp) </br>\n",
        "\n",
        "4. [**REFERENCES**](#references)\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "fufalX8dNHNb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Objectives**\n",
        "- Understand how perceptrons are originated and created.\n",
        "- Advance from Single-Layer Perceptrons to Multi-Layer Perceptrons.\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "c3VOs9M_NOeC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Prerequisites**\n",
        "- Install PyTorch and some extra packages.\n",
        "- Have Python and a Jupyter Notebook ready (great for interactive demos)."
      ],
      "metadata": {
        "id": "qCB_qfHWNQ_i"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Installing Pytorch (for all setups in `00-setup.ipynb` from the hands-on 00):\n",
        "\n",
        "- `pip install torch torchvision`\n",
        "\n",
        "- `pip install nbformat`\n",
        "\n",
        "- `pip install torchmetrics`\n",
        "\n",
        "- To plot pretty graphs, you can use Plotly\n",
        "`pip install plotly`\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "Y5eav4EvNTny"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Basic concept**:\n",
        "\n",
        "### 1. Perceptron\n",
        "\n",
        "**Definition:**\n",
        "The Perceptron is the simplest form of neural network, consisting of a single artificial neuron. It takes multiple inputs, applies weights to them, sums them together with a bias term, and passes the result through a step activation function to produce a binary output.\n",
        "\n",
        "**Formula:**\n",
        "$y = \\text{step}(w_0 + w_1x_1 + w_2x_2 + ... + w_nx_n)$\n",
        "\n",
        "Where:\n",
        "- $y$ is the output (0 or 1)\n",
        "- $x_i$ are the inputs\n",
        "- $w_i$ are the weights\n",
        "- $w_0$ is the bias term\n",
        "- $\\text{step}(z) = \\begin{cases} 1 & \\text{if } z \\geq 0 \\\\ 0 & \\text{if } z < 0 \\end{cases}$"
      ],
      "metadata": {
        "id": "1aHdZxanOt7l"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8QB0-cd-MXJt"
      },
      "outputs": [],
      "source": [
        "import plotly.graph_objects as go\n",
        "\n",
        "node_size = 40\n",
        "font_size = 12\n",
        "layer_colors = {'input': '#636EFA', 'bias': '#00CC96',\n",
        "               'hidden': '#FFA15A', 'output': '#EF553B',\n",
        "               'activation': '#AB63FA'}\n",
        "\n",
        "def create_network(nodes, edges, title):\n",
        "    fig = go.Figure()\n",
        "    legend_groups = set()\n",
        "\n",
        "    # Create edges with weights\n",
        "    for i, ((src, dest), weight) in enumerate(edges.items()):\n",
        "        x0, y0 = nodes[src]['x'], nodes[src]['y']\n",
        "        x1, y1 = nodes[dest]['x'], nodes[dest]['y']\n",
        "        fig.add_trace(go.Scatter(\n",
        "            x=[x0, x1, None], y=[y0, y1, None],\n",
        "            line=dict(width=1, color='gray'),\n",
        "            mode='lines',\n",
        "            hoverinfo='text',\n",
        "            text=f'Weight: {weight}',\n",
        "            showlegend=i == 0,\n",
        "            legendgroup='weights',\n",
        "            name='Weights'\n",
        "        ))\n",
        "\n",
        "    # Create nodes with legend groups\n",
        "    for node in nodes:\n",
        "        # Determine node type from color\n",
        "        node_type = [k for k, v in layer_colors.items() if v == node['color']][0]\n",
        "\n",
        "        fig.add_trace(go.Scatter(\n",
        "            x=[node['x']], y=[node['y']],\n",
        "            mode='markers+text',\n",
        "            marker=dict(size=node_size, color=node['color']),\n",
        "            text=node.get('label', ''),\n",
        "            textposition=\"top center\",\n",
        "            hoverinfo='text',\n",
        "            hovertext=node.get('formula', ''),\n",
        "            showlegend=node_type not in legend_groups,\n",
        "            legendgroup=node_type,\n",
        "            name=f'{node_type.capitalize()} Node'\n",
        "        ))\n",
        "        if node_type not in legend_groups:\n",
        "            legend_groups.add(node_type)\n",
        "\n",
        "    # Add activation functions as separate traces\n",
        "    activation_added = False\n",
        "    for node in nodes:\n",
        "        if 'activation' in node:\n",
        "            fig.add_trace(go.Scatter(\n",
        "                x=[node['x'] + 0.25],  # Offset from node\n",
        "                y=[node['y'] + 0.1],   # Vertical adjustment\n",
        "                mode='text',\n",
        "                text=node['activation'],\n",
        "                textfont=dict(color=layer_colors['activation'], size=font_size),\n",
        "                showlegend=not activation_added,\n",
        "                legendgroup='activation',\n",
        "                name='Activation Function'\n",
        "            ))\n",
        "            activation_added = True\n",
        "\n",
        "    fig.update_layout(\n",
        "        title=title,\n",
        "        template='plotly_white',\n",
        "        xaxis=dict(showgrid=False, zeroline=False, showticklabels=False),\n",
        "        yaxis=dict(showgrid=False, zeroline=False, showticklabels=False),\n",
        "        margin=dict(l=20, r=150),\n",
        "        legend=dict(\n",
        "            x=1.05,\n",
        "            y=0.5,\n",
        "            xanchor='left',\n",
        "            yanchor='middle',\n",
        "            itemsizing='constant'\n",
        "        )\n",
        "    )\n",
        "    return fig"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --------------------------------------------------------------------------\n",
        "# 1. Perceptron\n",
        "# --------------------------------------------------------------------------\n",
        "perceptron_nodes = [\n",
        "    {'x': 0, 'y': 1, 'label': '1', 'color': layer_colors['bias'],\n",
        "     'formula': 'Bias (always 1)'},\n",
        "    {'x': 0, 'y': 0, 'label': 'x₁', 'color': layer_colors['input']},\n",
        "    {'x': 0, 'y': -1, 'label': 'x₂', 'color': layer_colors['input']},\n",
        "    {'x': 1, 'y': 0, 'label': 'y', 'color': layer_colors['output'],\n",
        "     'activation': 'step(Σ)',\n",
        "     'formula': 'Output: y = step(w₀ + w₁x₁ + w₂x₂)'}\n",
        "]\n",
        "\n",
        "perceptron_edges = {\n",
        "    (0,3): 'w₀',\n",
        "    (1,3): 'w₁',\n",
        "    (2,3): 'w₂'\n",
        "}\n",
        "\n",
        "fig1 = create_network(perceptron_nodes, perceptron_edges, \"Perceptron\")\n",
        "fig1.show()"
      ],
      "metadata": {
        "id": "BPB4101JO0vK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Single-Layer Perceptron (SLP)\n",
        "\n",
        "**Definition:**\n",
        "A Single-Layer Perceptron extends the basic perceptron by including multiple output neurons, allowing it to classify inputs into more than two categories. It still has a single layer of computation (the output layer) with direct connections from all inputs to all outputs.\n",
        "\n",
        "**Formula:**\n",
        "For each output neuron $j$:\n",
        "$y_j = \\text{step}(\\sum_{i=0}^{n} w_{ij}x_i)$\n",
        "\n",
        "Where:\n",
        "- $y_j$ is the output of the $j$-th output neuron\n",
        "- $x_i$ are the inputs (with $x_0 = 1$ for the bias)\n",
        "- $w_{ij}$ is the weight from input $i$ to output neuron $j$"
      ],
      "metadata": {
        "id": "CwzUBUU5O41a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --------------------------------------------------------------------------\n",
        "# 2. Single-Layer Perceptron\n",
        "# --------------------------------------------------------------------------\n",
        "slp_nodes = [\n",
        "    {'x': 0, 'y': 1, 'label': '1', 'color': layer_colors['bias']},\n",
        "    {'x': 0, 'y': 0, 'label': 'x₁', 'color': layer_colors['input']},\n",
        "    {'x': 0, 'y': -1, 'label': 'x₂', 'color': layer_colors['input']},\n",
        "    {'x': 1, 'y': 0.5, 'label': 'y₁', 'color': layer_colors['output'],\n",
        "     'activation': 'step(Σ)', 'formula': 'y₁ = step(Σwᵢxᵢ + b₁)'},\n",
        "    {'x': 1, 'y': -0.5, 'label': 'y₂', 'color': layer_colors['output'],\n",
        "     'activation': 'step(Σ)', 'formula': 'y₂ = step(Σwⱼxⱼ + b₂)'}\n",
        "]\n",
        "\n",
        "slp_edges = {\n",
        "    (0,3): 'w₀₁', (0,4): 'w₀₂',\n",
        "    (1,3): 'w₁₁', (1,4): 'w₁₂',\n",
        "    (2,3): 'w₂₁', (2,4): 'w₂₂'\n",
        "}\n",
        "\n",
        "fig2 = create_network(slp_nodes, slp_edges, \"Single-Layer Perceptron (SLP)\")\n",
        "fig2.show()"
      ],
      "metadata": {
        "id": "JZwDXHFwO8Ga"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Multi-Layer Perceptron (MLP)\n",
        "\n",
        "**Definition:**\n",
        "A Multi-Layer Perceptron introduces one or more hidden layers between the input and output layers. This allows the network to learn non-linear relationships and solve problems that aren't linearly separable. Each neuron typically uses non-linear activation functions like ReLU or sigmoid.\n",
        "\n",
        "**Formula:**\n",
        "For a MLP with one hidden layer:\n",
        "\n",
        "Hidden layer: For each hidden neuron $h_k$:\n",
        "$h_k = \\text{activation}_h(\\sum_{i=0}^{n} w_{ik}^{(1)}x_i)$\n",
        "\n",
        "Output layer: For each output neuron $y_j$:\n",
        "$y_j = \\text{activation}_o(\\sum_{k=0}^{m} w_{kj}^{(2)}h_k)$\n",
        "\n",
        "Where:\n",
        "- $h_k$ is the output of the $k$-th hidden neuron\n",
        "- $y_j$ is the output of the $j$-th output neuron\n",
        "- $w_{ik}^{(1)}$ is the weight from input $i$ to hidden neuron $k$\n",
        "- $w_{kj}^{(2)}$ is the weight from hidden neuron $k$ to output neuron $j$\n",
        "- $\\text{activation}_h$ and $\\text{activation}_o$ are activation functions (e.g., ReLU, sigmoid, tanh)"
      ],
      "metadata": {
        "id": "woBz0LXCO_AS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --------------------------------------------------------------------------\n",
        "# 3. Multi-Layer Perceptron\n",
        "# --------------------------------------------------------------------------\n",
        "mlp_nodes = [\n",
        "    {'x': 0, 'y': 1, 'label': '1', 'color': layer_colors['bias']},\n",
        "    {'x': 0, 'y': 0, 'label': 'x₁', 'color': layer_colors['input']},\n",
        "    {'x': 0, 'y': -1, 'label': 'x₂', 'color': layer_colors['input']},\n",
        "    {'x': 1, 'y': 1, 'label': 'h₁', 'color': layer_colors['hidden'],\n",
        "     'activation': 'ReLU(Σ)', 'formula': 'h₁ = ReLU(Σwᵢxᵢ + b₁)'},\n",
        "    {'x': 1, 'y': -1, 'label': 'h₂', 'color': layer_colors['hidden'],\n",
        "     'activation': 'ReLU(Σ)', 'formula': 'h₂ = ReLU(Σwⱼxⱼ + b₂)'},\n",
        "    {'x': 2, 'y': 0, 'label': 'y', 'color': layer_colors['output'],\n",
        "     'activation': 'σ(Σ)', 'formula': 'y = sigmoid(Σwₖhₖ + b₃)'}\n",
        "]\n",
        "\n",
        "mlp_edges = {\n",
        "    (0,3): 'w₀₁', (0,4): 'w₀₂',\n",
        "    (1,3): 'w₁₁', (1,4): 'w₁₂',\n",
        "    (2,3): 'w₂₁', (2,4): 'w₂₂',\n",
        "    (3,5): 'w₃₁',\n",
        "    (4,5): 'w₄₁'\n",
        "}\n",
        "\n",
        "fig3 = create_network(mlp_nodes, mlp_edges, \"Multi-Layer Perceptron (MLP)\")\n",
        "fig3.show()"
      ],
      "metadata": {
        "id": "z9SAW5r4PCR8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Implementation of a MLP**\n",
        "\n",
        "Multi-Layer Perceptron (MLP)\n",
        "\n",
        "An MLP is a fully connected neural network used for tasks like classification. We'll classify MNIST digits."
      ],
      "metadata": {
        "id": "03VAPfvFUHqD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install Pytorch (if not installed) with libraries to handle vision/image operations (Torchvision) and get metrics (Torchmetrics)\n",
        "!pip install torch torchvision torchmetrics"
      ],
      "metadata": {
        "id": "amTqEvTJUKPZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import plotly.graph_objects as go\n",
        "import numpy as np\n",
        "\n",
        "layer_colors = {\n",
        "    'input': '#636EFA',\n",
        "    'flatten': '#EF553B',\n",
        "    'fc': '#AB63FA',\n",
        "    'output': '#19D3F3',\n",
        "    'activation': '#FF6692'\n",
        "}\n",
        "\n",
        "layer_descriptions = {\n",
        "    'input': \"Input Layer\\n28×28×1 grayscale image\",\n",
        "    'flatten': \"Flatten Layer\\nConverts 2D image to 1D vector (784 features)\",\n",
        "    'fc': \"Fully Connected Layer\\nLearns global patterns with ReLU activation\",\n",
        "    'output': \"Output Layer\\n10 units (one per class)\"\n",
        "}\n",
        "\n",
        "def create_mlp_visualization():\n",
        "    fig = go.Figure()\n",
        "    x_positions = [0, 2, 4, 6, 8]\n",
        "    legend_groups = set()\n",
        "\n",
        "    # Input layer\n",
        "    create_3d_layer(fig, x_positions[0], 3, 3, 'input', 'Input\\n28×28×1',\n",
        "                   legend_groups, layer_descriptions['input'])\n",
        "\n",
        "    # Flatten layer\n",
        "    add_flatten_layer(fig, x_positions[1], legend_groups,\n",
        "                     layer_descriptions['flatten'])\n",
        "\n",
        "    # Fully Connected layers\n",
        "    fc_layers = [\n",
        "        {'units': 128, 'label': '128', 'activation': 'ReLU', 'type': 'fc'},\n",
        "        {'units': 64, 'label': '64', 'activation': 'ReLU', 'type': 'fc'},\n",
        "        {'units': 10, 'label': '10', 'activation': None, 'type': 'output'}\n",
        "    ]\n",
        "\n",
        "    for i, layer in enumerate(fc_layers):\n",
        "        x = x_positions[2 + i]\n",
        "        add_fc_layer(fig, x, layer['units'], layer['label'],\n",
        "                    layer['type'], legend_groups, layer['activation'],\n",
        "                    layer_descriptions[layer['type']])\n",
        "\n",
        "    add_mlp_connections(fig, x_positions)\n",
        "\n",
        "    fig.update_layout(\n",
        "        title=dict(\n",
        "            text=\"Multilayer Perceptron (MLP) Architecture\",\n",
        "            x=0.05,\n",
        "            font=dict(size=24)\n",
        "        ),\n",
        "        template='plotly_white',\n",
        "        margin=dict(l=20, r=300, t=100, b=20),\n",
        "        legend=dict(\n",
        "            title=\"Layer Types\",\n",
        "            x=1.05,\n",
        "            y=0.5,\n",
        "            xanchor='left',\n",
        "            yanchor='middle',\n",
        "            font=dict(size=12)),\n",
        "        width=1400,\n",
        "        height=600,\n",
        "        scene=dict(\n",
        "            xaxis=dict(showgrid=False, zeroline=False, visible=False),\n",
        "            yaxis=dict(showgrid=False, zeroline=False, visible=False),\n",
        "            zaxis=dict(showgrid=False, zeroline=False, visible=False),\n",
        "            aspectmode='manual',\n",
        "            aspectratio=dict(x=2, y=1, z=0.5)),\n",
        "        annotations=[dict(\n",
        "            x=1.05,\n",
        "            y=0.9,\n",
        "            xref='paper',\n",
        "            yref='paper',\n",
        "            text=\"<b>MLP Components:</b><br>\"\n",
        "                 \"- Flatten: 2D→1D conversion<br>\"\n",
        "                 \"- Fully Connected: Dense layers<br>\"\n",
        "                 \"- ReLU: Non-linear activation\",\n",
        "            showarrow=False,\n",
        "            align='left',\n",
        "            font=dict(size=14))])\n",
        "    return fig\n",
        "\n",
        "def create_3d_layer(fig, x_pos, height, depth, layer_type, label_text,\n",
        "                   legend_groups, description):\n",
        "    # 3D box coordinates\n",
        "    x = [x_pos, x_pos+1.2, x_pos+1.2, x_pos] * 2\n",
        "    y = [-height/2, -height/2, height/2, height/2] * 2\n",
        "    z = [0]*4 + [depth]*4\n",
        "\n",
        "    edges = [(0,1), (1,2), (2,3), (3,0), (4,5), (5,6), (6,7), (7,4), (0,4), (1,5), (2,6), (3,7)]\n",
        "\n",
        "    for i, (start, end) in enumerate(edges):\n",
        "        show_legend = (layer_type not in legend_groups) and (i == 0)\n",
        "        fig.add_trace(go.Scatter3d(\n",
        "            x=[x[start], x[end]],\n",
        "            y=[y[start], y[end]],\n",
        "            z=[z[start], z[end]],\n",
        "            mode='lines',\n",
        "            line=dict(color=layer_colors[layer_type], width=2),\n",
        "            showlegend=show_legend,\n",
        "            name=layer_descriptions[layer_type].split('\\n')[0],\n",
        "            legendgroup=layer_type,\n",
        "            hoverinfo='text',\n",
        "            hovertext=description))\n",
        "    if layer_type not in legend_groups:\n",
        "        legend_groups.add(layer_type)\n",
        "\n",
        "    # Layer label\n",
        "    fig.add_trace(go.Scatter3d(\n",
        "        x=[x_pos+0.6],\n",
        "        y=[-height/2 - 0.5],\n",
        "        z=[0],\n",
        "        mode='text',\n",
        "        text=label_text,\n",
        "        textfont=dict(color='black', size=14),\n",
        "        hoverinfo='none',\n",
        "        showlegend=False))\n",
        "\n",
        "def add_flatten_layer(fig, x_pos, legend_groups, description):\n",
        "    y_values = np.linspace(-1, 1, 20)\n",
        "    fig.add_trace(go.Scatter3d(\n",
        "        x=[x_pos]*20,\n",
        "        y=y_values,\n",
        "        z=[0]*20,\n",
        "        mode='lines',\n",
        "        line=dict(color=layer_colors['flatten'], width=6),\n",
        "        showlegend='flatten' not in legend_groups,\n",
        "        name=layer_descriptions['flatten'].split('\\n')[0],\n",
        "        legendgroup='flatten',\n",
        "        hoverinfo='text',\n",
        "        hovertext=description))\n",
        "    legend_groups.add('flatten')\n",
        "\n",
        "def add_fc_layer(fig, x_pos, units, label, layer_type, legend_groups, activation, description):\n",
        "    # Add nodes\n",
        "    num_nodes = min(units, 20)  # Limit nodes for visualization\n",
        "    y_values = np.linspace(-0.8, 0.8, num_nodes)\n",
        "\n",
        "    fig.add_trace(go.Scatter3d(\n",
        "        x=[x_pos]*num_nodes,\n",
        "        y=y_values,\n",
        "        z=[0]*num_nodes,\n",
        "        mode='markers',\n",
        "        marker=dict(size=6, color=layer_colors[layer_type]),\n",
        "        showlegend=layer_type not in legend_groups,\n",
        "        name=description.split('\\n')[0],\n",
        "        legendgroup=layer_type,\n",
        "        hoverinfo='text',\n",
        "        hovertext=f\"{description}\\nUnits: {units}\"))\n",
        "\n",
        "    if layer_type not in legend_groups:\n",
        "        legend_groups.add(layer_type)\n",
        "\n",
        "    # Activation annotation\n",
        "    if activation:\n",
        "        fig.add_trace(go.Scatter3d(\n",
        "            x=[x_pos + 0.3],\n",
        "            y=[0.9],\n",
        "            z=[0],\n",
        "            mode='text',\n",
        "            text=f'σ = {activation}',\n",
        "            textfont=dict(color=layer_colors['activation'], size=14),\n",
        "            showlegend=False))\n",
        "\n",
        "    # Layer label\n",
        "    fig.add_trace(go.Scatter3d(\n",
        "        x=[x_pos],\n",
        "        y=[-1.2],\n",
        "        z=[0],\n",
        "        mode='text',\n",
        "        text=label,\n",
        "        textfont=dict(color='black', size=14),\n",
        "        showlegend=False))\n",
        "\n",
        "def add_mlp_connections(fig, x_positions):\n",
        "    operations = [\n",
        "        (\"Flatten\", \"28×28→784\", \"\"),\n",
        "        (\"Fully Connected\", \"784→128\", \"ReLU\"),\n",
        "        (\"Fully Connected\", \"128→64\", \"ReLU\"),\n",
        "        (\"Fully Connected\", \"64→10\", \"\")\n",
        "    ]\n",
        "\n",
        "    for i in range(len(x_positions)-1):\n",
        "        x_start = x_positions[i] + 1.2\n",
        "        x_end = x_positions[i+1]\n",
        "\n",
        "        fig.add_trace(go.Scatter3d(\n",
        "            x=np.linspace(x_start, x_end, 30),\n",
        "            y=np.zeros(30),\n",
        "            z=np.zeros(30),\n",
        "            mode='lines',\n",
        "            line=dict(color='gray', width=1),\n",
        "            hoverinfo='text',\n",
        "            hovertext=f\"Operation: {operations[i][0]}<br>{operations[i][1]}<br>{operations[i][2]}\",\n",
        "            showlegend=False))\n",
        "\n",
        "        fig.add_trace(go.Scatter3d(\n",
        "            x=[(x_start + x_end)/2],\n",
        "            y=[0.5],\n",
        "            z=[0],\n",
        "            mode='text',\n",
        "            text=operations[i][0],\n",
        "            textfont=dict(size=12, color='black'),\n",
        "            showlegend=False))\n",
        "\n",
        "# Generate and display the visualization\n",
        "mlp_fig = create_mlp_visualization()\n",
        "mlp_fig.show()"
      ],
      "metadata": {
        "id": "BSFOHF59XtQF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "from torchmetrics import Accuracy\n",
        "from tqdm import tqdm\n",
        "import plotly.graph_objects as go\n",
        "\n",
        "# Device configuration\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Define the MLP model\n",
        "class MLP(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MLP, self).__init__()\n",
        "        self.fc1 = nn.Linear(28*28, 128)\n",
        "        self.fc2 = nn.Linear(128, 64)\n",
        "        self.fc3 = nn.Linear(64, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(-1, 28*28)\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = torch.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "# Data loading\n",
        "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
        "train_dataset = datasets.MNIST(root='./data', train=True, transform=transform, download=True)\n",
        "\n",
        "train_set, val_set = random_split(train_dataset, [55000, 5000])  # 55k train, 5k val\n",
        "\n",
        "train_loader = DataLoader(train_set, batch_size=64, shuffle=True)\n",
        "val_loader = DataLoader(val_set, batch_size=64, shuffle=False)\n",
        "\n",
        "test_dataset = datasets.MNIST(root='./data', train=False, transform=transform)\n",
        "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
        "\n",
        "# Training setup\n",
        "model = MLP()\n",
        "\n",
        "# Set mode to run on GPU\n",
        "model = model.to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "accuracy = Accuracy(task=\"multiclass\", num_classes=10)\n",
        "\n",
        "# Lists to store losses\n",
        "train_losses = []\n",
        "val_losses = []\n",
        "\n",
        "num_epochs = 5\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    train_loss = 0.0\n",
        "    for images, labels in tqdm(train_loader, desc=f'Epoch {epoch+1}/{num_epochs}'):\n",
        "        images, labels = images.to(device), labels.to(device)  # Move data to GPU\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        train_loss += loss.item()\n",
        "    train_losses.append(train_loss / len(train_loader))\n",
        "\n",
        "    # Validation\n",
        "    model.eval()\n",
        "    val_loss = 0\n",
        "    val_acc = 0\n",
        "    with torch.no_grad():\n",
        "        for images, labels in val_loader:\n",
        "            images, labels = images.to(device), labels.to(device)  # Move data to GPU\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            val_loss += loss.item()\n",
        "            accuracy.update(outputs, labels)\n",
        "\n",
        "    val_losses.append(val_loss / len(val_loader))\n",
        "    val_acc = accuracy.compute()\n",
        "    print(f'Epoch {epoch+1}, Train Loss: {train_losses[-1]:.4f}, Val Loss: {val_losses[-1]:.4f}, Val Accuracy: {val_acc:.2f}')\n",
        "    accuracy.reset()\n",
        "\n",
        "# Test set evaluation\n",
        "model.eval()\n",
        "test_loss = 0.0\n",
        "test_acc = 0.0\n",
        "with torch.no_grad():\n",
        "    for images, labels in test_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        test_loss += loss.item()\n",
        "        accuracy.update(outputs, labels)\n",
        "    test_loss /= len(test_loader)\n",
        "    test_acc = accuracy.compute()\n",
        "    print(f'Test Loss: {test_loss:.4f}, Test Accuracy: {test_acc:.2f}')\n",
        "\n",
        "# Plot losses\n",
        "fig = go.Figure()\n",
        "fig.add_trace(go.Scatter(\n",
        "    x=list(range(1, len(train_losses)+1)),\n",
        "    y=train_losses,\n",
        "    mode='lines+markers',\n",
        "    name='Train Loss',\n",
        "    line=dict(color='blue')\n",
        "))\n",
        "\n",
        "fig.add_trace(go.Scatter(\n",
        "    x=list(range(1, len(val_losses)+1)),\n",
        "    y=val_losses,\n",
        "    mode='lines+markers',\n",
        "    name='Val Loss',\n",
        "    line=dict(color='red')\n",
        "))\n",
        "\n",
        "fig.update_layout(\n",
        "    title='MLP Training Progress',\n",
        "    xaxis_title='Epoch',\n",
        "    yaxis_title='Loss',\n",
        "    template='plotly_white',\n",
        "    legend=dict(x=0.8, y=0.9),\n",
        "    margin=dict(l=40, r=20, t=40, b=20)\n",
        ")\n",
        "\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "aX9IMX2hUQpe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import plotly.subplots as sp\n",
        "import numpy as np\n",
        "\n",
        "# Collect predictions from the test set\n",
        "model.eval()\n",
        "images_list = []\n",
        "true_labels = []\n",
        "pred_labels = []\n",
        "correctness = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, labels in test_loader:\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        images_list.append(images.cpu().numpy())\n",
        "        true_labels.append(labels.cpu().numpy())\n",
        "        pred_labels.append(predicted.cpu().numpy())\n",
        "        correctness.append(predicted == labels)\n",
        "\n",
        "# Concatenate all batches\n",
        "images_list = np.concatenate(images_list, axis=0)\n",
        "true_labels = np.concatenate(true_labels, axis=0)\n",
        "pred_labels = np.concatenate(pred_labels, axis=0)\n",
        "correctness = np.concatenate(correctness, axis=0)\n",
        "\n",
        "# Select a subset to display (e.g., 25 images)\n",
        "num_display = 25\n",
        "indices = np.random.choice(len(images_list), num_display, replace=False)\n",
        "selected_images = images_list[indices]\n",
        "selected_true = true_labels[indices]\n",
        "selected_pred = pred_labels[indices]\n",
        "selected_correct = correctness[indices]\n",
        "\n",
        "# Create a subplot grid\n",
        "rows, cols = 5, 5\n",
        "fig = sp.make_subplots(rows=rows, cols=cols, subplot_titles=[f\"True: {t}, Pred: {p}\" for t, p in zip(selected_true, selected_pred)])\n",
        "\n",
        "for i in range(num_display):\n",
        "    row = i // cols + 1\n",
        "    col = i % cols + 1\n",
        "    img = selected_images[i].squeeze()  # Remove channel dimension\n",
        "    img = (img * 0.5 + 0.5)  # Denormalize to [0, 1]\n",
        "    img = np.flipud(img)  # Flip vertically to correct orientation\n",
        "\n",
        "    # Add image to subplot\n",
        "    fig.add_trace(\n",
        "        go.Heatmap(z=img, colorscale='gray', showscale=False),\n",
        "        row=row, col=col\n",
        "    )\n",
        "\n",
        "    # Update title color based on correctness\n",
        "    title_color = 'green' if selected_correct[i] else 'red'\n",
        "    fig.layout.annotations[i].update(font=dict(color=title_color))\n",
        "\n",
        "# Update layout\n",
        "fig.update_layout(\n",
        "    title_text=\"MNIST Classification Results (Green: Correct, Red: Incorrect)\",\n",
        "    height=800,\n",
        "    width=800,\n",
        "    showlegend=False\n",
        ")\n",
        "\n",
        "# Remove axes for cleaner visualization\n",
        "for i in range(1, num_display + 1):\n",
        "    fig.update_xaxes(showticklabels=False, showgrid=False, zeroline=False, row=(i-1)//cols+1, col=(i-1)%cols+1)\n",
        "    fig.update_yaxes(showticklabels=False, showgrid=False, zeroline=False, row=(i-1)//cols+1, col=(i-1)%cols+1)\n",
        "\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "5zBHLTy8U12x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Exercise**: Change the number of neurons in the hidden layers (e.g., 128 to 256) and observe the impact on the loss curves and accuracy."
      ],
      "metadata": {
        "id": "zLq1a3SkU9Zv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **REFERENCES**\n",
        "\n",
        "**This hands-on was based or inspired on the following reference materials:**\n",
        "\n",
        "- PyTorch Official Documentation [1]\n",
        "- PyTorch Tutorials [2]\n",
        "- Learn PyTorch for Deep Learning: Zero to Mastery [3]\n",
        "\n",
        "\n",
        "[1] PyTorch (2025). PyTorch documentation. The Linux Foundation. https://docs.pytorch.org/docs/stable/index.html\n",
        "\n",
        "[2] PyTorch (2024). Welcome to PyTorch Tutorials. The Linux Foundation. https://docs.pytorch.org/tutorials/\n",
        "\n",
        "[3] Learn Pytorch (2023). Learn PyTorch for Deep Learning: Zero to Mastery. By Daniel Bourke. https://www.learnpytorch.io/"
      ],
      "metadata": {
        "id": "T1aK5euDPUl6"
      }
    }
  ]
}